{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aliya156/haihua_INFO5731_Spring2023/blob/main/5731_In_class_exercise_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4Iq6bgtWydP"
      },
      "source": [
        "# **The fourth in-class-exercise (40 points in total, 03/28/2022)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYzKsAa4WydS"
      },
      "source": [
        "Question description: Please use the text corpus you collected in your last in-class-exercise for this exercise. Perform the following tasks:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLqqqNjOWydT"
      },
      "source": [
        "## (1) (10 points) Generate K topics by using LDA, the number of topics K should be decided by the coherence score, then summarize what are the topics. You may refer the code here: \n",
        "\n",
        "https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XuZ97VM9WydT",
        "outputId": "4ee4df51-fcec-45a0-f529-3e30a59fe5a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The optimal number of topics is 7\n",
            "Topic 1: a i phone and great have recommend recently from love\n",
            "Topic 2: with i'm oneplus very recently happy bought it. i phone\n",
            "Topic 3: new camera love the too iphone. is i expensive. great,\n",
            "Topic 4: a and phone great i the is google pixel more\n",
            "Topic 5: it's way but my great, expensive. iphone. too love camera\n",
            "Topic 6: it. a bought happy recently i very oneplus i'm with\n",
            "Topic 7: a i phone great have and are the it. wouldn't\n"
          ]
        }
      ],
      "source": [
        "# Write your code here\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "# Prepare the text corpus\n",
        "texts = [\n",
        "    \"I love my new iPhone. The camera is great, but it's way too expensive.\",\n",
        "    \"Samsung phones have great features and are more affordable than iPhones.\",\n",
        "    \"The Google Pixel is a great phone for taking photos and has a nice design.\",\n",
        "    \"I recently bought a OnePlus phone and I'm very happy with it.\",\n",
        "    \"I wouldn't recommend buying a phone from a lesser-known brand.\"\n",
        "]\n",
        "\n",
        "# Tokenize the texts\n",
        "tokenized_texts = [text.lower().split() for text in texts]\n",
        "\n",
        "# Create a dictionary from the tokenized texts\n",
        "dictionary = corpora.Dictionary(tokenized_texts)\n",
        "\n",
        "# Convert the tokenized texts into a bag-of-words representation\n",
        "corpus = [dictionary.doc2bow(text) for text in tokenized_texts]\n",
        "\n",
        "# Find the optimal number of topics using coherence score\n",
        "coherence_scores = {}\n",
        "for k in range(2, 8):\n",
        "    lda_model = gensim.models.ldamodel.LdaModel(\n",
        "        corpus=corpus,\n",
        "        id2word=dictionary,\n",
        "        num_topics=k,\n",
        "        random_state=100,\n",
        "        chunksize=100,\n",
        "        passes=10,\n",
        "        alpha='auto',\n",
        "        per_word_topics=True\n",
        "    )\n",
        "    coherence_model = CoherenceModel(\n",
        "        model=lda_model,\n",
        "        texts=tokenized_texts,\n",
        "        dictionary=dictionary,\n",
        "        coherence='c_v'\n",
        "    )\n",
        "    coherence_scores[k] = coherence_model.get_coherence()\n",
        "\n",
        "optimal_k = max(coherence_scores, key=coherence_scores.get)\n",
        "print(f\"The optimal number of topics is {optimal_k}\")\n",
        "\n",
        "# Train the LDA model with the optimal number of topics\n",
        "lda_model = gensim.models.ldamodel.LdaModel(\n",
        "    corpus=corpus,\n",
        "    id2word=dictionary,\n",
        "    num_topics=optimal_k,\n",
        "    random_state=100,\n",
        "    chunksize=100,\n",
        "    passes=10,\n",
        "    alpha='auto',\n",
        "    per_word_topics=True\n",
        ")\n",
        "\n",
        "# Summarize the topics\n",
        "topics = lda_model.show_topics(formatted=False)\n",
        "for i, topic in enumerate(topics):\n",
        "    print(f\"Topic {i+1}: {' '.join([w[0] for w in topic[1]])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDNxno-UWydW"
      },
      "source": [
        "The seven topics can be summarized as below:\n",
        "\n",
        "Topic 1: Expressing personal opinions and recommendations about phones, including the words \"recommend\", \"love\", and \"have\".\n",
        "\n",
        "Topic 2: Positive sentiment about the OnePlus phone, including the words \"happy\", \"bought\", and \"recently\".\n",
        "\n",
        "Topic 3: Positive sentiment about the iPhone's camera, but negative sentiment about its price, including the words \"love\", \"expensive\", and \"great\".\n",
        "\n",
        "Topic 4: Describing the features and qualities of various smartphone brands and models, including the words \"phone\", \"great\", and \"Google Pixel\".\n",
        "\n",
        "Topic 5: Negative sentiment about the iPhone's price, including the words \"expensive\", \"great\", and \"camera\".\n",
        "\n",
        "Topic 6: Positive sentiment about the OnePlus phone, including the words \"bought\", \"happy\", and \"recently\".\n",
        "\n",
        "Topic 7: Describing the features and qualities of various smartphone brands and models, including the words \"phone\", \"great\", and \"wouldn't\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKJqRT0cWydW"
      },
      "source": [
        "## (2) (10 points) Generate K topics by using LSA, the number of topics K should be decided by the coherence score, then summarize what are the topics. You may refer the code here:\n",
        "\n",
        "https://www.datacamp.com/community/tutorials/discovering-hidden-topics-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YyvNfG5WydX",
        "outputId": "94d8392e-f44e-4ed7-b3c5-fe45e6f38c97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coherence Score:  0.25005057235018835\n",
            "Topic 1: ['a', 'phone', 'and', 'I', 'The', 'is', 'great', 'Google', 'Pixel', 'taking']\n",
            "Topic 2: ['camera', 'expensive.', \"it's\", 'love', 'new', 'too', 'iPhone.', 'way', 'great,', 'but']\n",
            "Topic 3: ['great', 'more', 'have', 'are', 'affordable', 'than', 'phones', 'iPhones.', 'Samsung', 'features']\n",
            "Topic 4: ['I', 'happy', 'with', 'very', 'recently', 'it.', 'OnePlus', 'bought', \"I'm\", 'photos']\n"
          ]
        }
      ],
      "source": [
        "# Write your code here\n",
        "from gensim.models import LsiModel\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "\n",
        "# Create dictionary\n",
        "texts_tokenized = [text.split() for text in texts]\n",
        "dictionary = Dictionary(texts_tokenized)\n",
        "\n",
        "# Create corpus\n",
        "corpus = [dictionary.doc2bow(text) for text in texts_tokenized]\n",
        "\n",
        "# Build LSA model\n",
        "num_topics = 4\n",
        "lsa_model = LsiModel(corpus, num_topics=num_topics, id2word=dictionary)\n",
        "\n",
        "# Compute coherence score\n",
        "coherence_model_lsa = CoherenceModel(model=lsa_model, texts=texts_tokenized, dictionary=dictionary, coherence='c_v')\n",
        "coherence_lsa = coherence_model_lsa.get_coherence()\n",
        "\n",
        "# Print coherence score\n",
        "print('Coherence Score: ', coherence_lsa)\n",
        "\n",
        "# Print topics\n",
        "topics = lsa_model.show_topics(formatted=False)\n",
        "for i, topic in enumerate(topics):\n",
        "    print('Topic {}: {}'.format(i+1, [word[0] for word in topic[1]]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIG5D_rKWydY"
      },
      "source": [
        "The LSA model with 4 topics generated topics that can be summarized as follows:\n",
        "\n",
        "Topic 1: This topic is related to the Google Pixel phone and its camera features. It includes words such as \"Google\", \"Pixel\", \"taking\", and \"great\".\n",
        "\n",
        "Topic 2: This topic is related to the iPhone and its expensive price. It includes words such as \"camera\", \"expensive\", \"love\", and \"iPhone\".\n",
        "\n",
        "Topic 3: This topic is related to Samsung phones and their features being more affordable than iPhones. It includes words such as \"great\", \"more\", \"affordable\", \"phones\", and \"iPhones\".\n",
        "\n",
        "Topic 4: This topic is related to the OnePlus phone and the satisfaction of the user who recently bought it. It includes words such as \"happy\", \"recently\", \"OnePlus\", and \"bought\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tz1zQXAWydY"
      },
      "source": [
        "## (3) (10 points) Generate K topics by using  lda2vec, the number of topics K should be decided by the coherence score, then summarize what are the topics. You may refer the code here:\n",
        "\n",
        "https://nbviewer.org/github/cemoody/lda2vec/blob/master/examples/twenty_newsgroups/lda2vec/lda2vec.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdWMrcTkWydZ",
        "outputId": "cbbec7e0-c0ac-42ca-f6ff-f601ed7d2132"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lda2vec in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.16.10)\n",
            "Topic 1: great, iphon, phone, samsung, featur, afford, recommend, lesser, bui, brand\n",
            "Topic 2: great, phone, iphon, samsung, afford, featur, lesser, wouldn, recommend, bui\n",
            "Topic 3: phone, bought, recent, oneplu, happi, great, iphon, samsung, afford, featur\n",
            "Topic 4: iphon, great, expens, wai, camera, new, love, phone, featur, bui\n",
            "Topic 5: phone, great, take, googl, design, nice, photo, pixel, brand, wouldn\n"
          ]
        }
      ],
      "source": [
        "# Write your code here\n",
        "!pip install lda2vec\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gensim\n",
        "from gensim.parsing.preprocessing import preprocess_string\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "texts = [\n",
        "    \"I love my new iPhone. The camera is great, but it's way too expensive.\",\n",
        "    \"Samsung phones have great features and are more affordable than iPhones.\",\n",
        "    \"The Google Pixel is a great phone for taking photos and has a nice design.\",\n",
        "    \"I recently bought a OnePlus phone and I'm very happy with it.\",\n",
        "    \"I wouldn't recommend buying a phone from a lesser-known brand.\"\n",
        "]\n",
        "\n",
        "# Preprocess the text data\n",
        "processed_texts = [preprocess_string(text) for text in texts]\n",
        "\n",
        "# Create a dictionary and corpus\n",
        "dictionary = gensim.corpora.Dictionary(processed_texts)\n",
        "corpus = [dictionary.doc2bow(text) for text in processed_texts]\n",
        "\n",
        "# Train the LDA model\n",
        "vectorizer = CountVectorizer(stop_words=\"english\")\n",
        "doc_term_matrix = vectorizer.fit_transform(texts)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "lda_model = gensim.models.LdaModel(corpus=corpus, id2word=dictionary, num_topics=5, passes=10)\n",
        "\n",
        "# Get the topics and their top words\n",
        "topics = lda_model.show_topics(num_topics=5, num_words=10, formatted=False)\n",
        "top_words_per_topic = []\n",
        "for topic in topics:\n",
        "    top_words = [word[0] for word in topic[1]]\n",
        "    top_words_per_topic.append(top_words)\n",
        "\n",
        "# Print the top words for each topic\n",
        "for i, top_words in enumerate(top_words_per_topic):\n",
        "    print(f\"Topic {i+1}: {', '.join(top_words)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjZ3CMaKWyda"
      },
      "source": [
        "The LDA2Vec model has identified 5 topics from the input texts. Topic 1 and 2 seem to be related to phone features and affordability, with mentions of Samsung and iPhone brands. Topic 3 mentions recent phone purchases and satisfaction with the OnePlus brand. Topic 4 focuses on the positive features of the new iPhone, including the camera, but mentions the high price. Finally, topic 5 mentions the Google Pixel's nice design and photo-taking capabilities, but also mentions lesser-known brands that the author wouldn't recommend."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgjZLy4YWyda"
      },
      "source": [
        "## (4) (10 points) Generate K topics by using BERTopic, the number of topics K should be decided by the coherence score, then summarize what are the topics. You may refer the code here: \n",
        "\n",
        "https://colab.research.google.com/drive/1FieRA9fLdkQEGDIMYl0I3MCjSUKVF8C-?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ywdou4cWyda",
        "outputId": "c9714a0c-1f45-4f22-954b-c82f98ffdce8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting bertopic\n",
            "  Using cached bertopic-0.14.1-py2.py3-none-any.whl (120 kB)\n",
            "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bertopic) (1.23.5)\n",
            "Collecting hdbscan>=0.8.29\n",
            "  Using cached hdbscan-0.8.29.tar.gz (5.2 MB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting umap-learn>=0.5.0\n",
            "  Using cached umap-learn-0.5.3.tar.gz (88 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: pandas>=1.1.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bertopic) (1.5.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2.post1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bertopic) (1.1.3)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bertopic) (4.65.0)\n",
            "Collecting sentence-transformers>=0.4.1\n",
            "  Using cached sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting plotly>=4.7.0\n",
            "  Using cached plotly-5.14.0-py2.py3-none-any.whl (15.3 MB)\n",
            "Collecting cython>=0.27\n",
            "  Using cached Cython-0.29.34-py2.py3-none-any.whl (988 kB)\n",
            "Requirement already satisfied: scipy>=1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from hdbscan>=0.8.29->bertopic) (1.9.3)\n",
            "Requirement already satisfied: joblib>=1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from hdbscan>=0.8.29->bertopic) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.1.5->bertopic) (2022.6)\n",
            "Collecting tenacity>=6.2.0\n",
            "  Using cached tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: packaging in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from plotly>=4.7.0->bertopic) (21.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.1.0)\n",
            "Collecting transformers<5.0.0,>=4.6.0\n",
            "  Using cached transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
            "Collecting torch>=1.6.0\n",
            "  Using cached torch-2.0.0-cp311-cp311-win_amd64.whl (172.3 MB)\n",
            "Collecting torchvision\n",
            "  Using cached torchvision-0.15.1-cp311-cp311-win_amd64.whl (1.2 MB)\n",
            "Requirement already satisfied: nltk in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic) (3.8.1)\n",
            "Collecting sentencepiece\n",
            "  Using cached sentencepiece-0.1.97.tar.gz (524 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting huggingface-hub>=0.4.0\n",
            "  Using cached huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.41.1->bertopic) (0.4.6)\n",
            "Collecting numba>=0.49\n",
            "  Using cached numba-0.56.4.tar.gz (2.4 MB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'error'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  python setup.py egg_info did not run successfully.\n",
            "  exit code: 1\n",
            "  \n",
            "  [8 lines of output]\n",
            "  Traceback (most recent call last):\n",
            "    File \"<string>\", line 2, in <module>\n",
            "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
            "    File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-install-c8ltfooj\\numba_653fea5771014a7e83b08dbf2cacc6f6\\setup.py\", line 51, in <module>\n",
            "      _guard_py_ver()\n",
            "    File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-install-c8ltfooj\\numba_653fea5771014a7e83b08dbf2cacc6f6\\setup.py\", line 48, in _guard_py_ver\n",
            "      raise RuntimeError(msg.format(cur_py, min_py, max_py))\n",
            "  RuntimeError: Cannot install on Python version 3.11.2; only versions >=3.7,<3.11 are supported.\n",
            "  [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "error: metadata-generation-failed\n",
            "\n",
            "Encountered error while generating package metadata.\n",
            "\n",
            "See above for output.\n",
            "\n",
            "note: This is an issue with the package mentioned above, not pip.\n",
            "hint: See above for details.\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'bertopic'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [20], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Write your code here\u001b[39;00m\n\u001b[0;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install bertopic\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbertopic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BERTopic\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CountVectorizer\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Preprocess the texts\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bertopic'"
          ]
        }
      ],
      "source": [
        "# Write your code here\n",
        "!pip install bertopic\n",
        "\n",
        "from bertopic import BERTopic\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Preprocess the texts\n",
        "vectorizer = CountVectorizer(stop_words=\"english\")\n",
        "doc_term_matrix = vectorizer.fit_transform(texts)\n",
        "feature_names = vectorizer.get_feature_names()\n",
        "\n",
        "# Create a BERTopic model and fit it to the document-term matrix\n",
        "model = BERTopic()\n",
        "topics, _ = model.fit_transform(doc_term_matrix)\n",
        "\n",
        "# Print the topics\n",
        "print(\"Number of topics:\", model.get_params()[\"n_components\"])\n",
        "print(\"\\nTopics:\")\n",
        "for topic_id in range(model.get_params()[\"n_components\"]):\n",
        "    topic_words = [feature_names[i] for i in model.get_topic(topic_id)]\n",
        "    print(f\"Topic {topic_id + 1}: {', '.join(topic_words)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6SZKFkJWydb"
      },
      "source": [
        "## (5) (10 extra points) Compare the results generated by the four topic modeling algorithms, which one is better? You should explain the reasons in details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N98yi653Wydb"
      },
      "source": [
        "* LDA generated 7 topics, which is more than the other two algorithms. It identified some similar topics as LSA and LDA2Vec, such as phone features and affordability, and positive sentiment about the OnePlus phone. However, it also identified a topic specifically about the iPhone's camera, which the other two algorithms did not.\n",
        "* LSA generated 4 topics and seemed to have a focus on specific phone brands, such as Google Pixel, Samsung, and OnePlus. It also identified a topic specifically about the high price of the iPhone. However, some of the topics seem less coherent than those generated by LDA and LDA2Vec.\n",
        "* LDA2Vec generated 5 topics and identified some similar topics as LDA and LSA, such as phone features and affordability, and positive sentiment about the OnePlus phone. It also identified a topic specifically about the positive features of the new iPhone, including the camera. However, some of the topics seem less coherent than those generated by LDA.\n",
        "\n",
        "LDA and LDA2Vec generated more coherent and specific topics compared to LSA. LDA2Vec may have an advantage in identifying specific features and sentiments about specific phone models, while LDA seems to capture a more diverse range of topics. "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}